emb:
  infeat_atom: 9
  infeat_bond: 3
  hidden: 128
  outfeat: 128
node:
  in_channels: 128
  hidden_channels: 64
  out_channels: 10
edge:
  num_embeddings: 10
  embedding_dim: 64
  h_graph_dim: 128
  input_size_rnn: 128
  hidden_size_rnn: 256
  num_layers: 2
  hidden_size_head: 64
  out_size_head: 4
train:
  data_size: 1000000
  batch_size: 1
  shuffle: true
  drop_last: true
  lr: 0.0001
  start_epoch: 0
  epoch: 100
  loss_weight:
  - 1
  - 1
  eval_step: 1
  save_step: 5
  model_dir: /ckpt/pretrain/freed/
  log_dir: /log/
  log_filename: pretrain-frag.txt
  vocab: /data/vocabulary/vocab-ring.pickle
  bond_loss_weight:
  - 1.0
  - 20.0
  - 20.0
  - 20.0
sample:
  model_dir: /ckpt/pretrain/ver2/
  max_step: 20
  num: 100
  model_ver: 20
  seed_smiles: C
rl:
  init_smiles: CCOc1ccc(OCC)c([C@H]2C(C#N)=C(N)N(c3ccccc3C(F)(F)F)C3=C2C(=O)CCC3)c1
  vocab: /data/vocabulary/vocab-ring.pickle
  model_ver_frag: 20
  model_ver_value: 0
  model_dir: /ckpt/pretrain/frag/normal/
  max_ep_len: 10
  max_training_timesteps: 3000000
  print_freq: 640
  log_freq: 20
  save_model_freq: 1000
  action_std: 0.6
  update_timestep: 640
  K_epochs: 10
  eps_clip: 0.2
  gamma: 0.99
  lr_actor: 0.0003
  lr_critic: 0.001
  random_seed: 0.0
  ckpt: /ckpt/rl/
  log_dir: /log/rl/
  log_filename: ppo.txt
exp:
  n_iter: 20
  seed_file: /Experiment/QED/seed_lowest_QED.csv
  out_dir: /Experiment/QED/result-10000/
